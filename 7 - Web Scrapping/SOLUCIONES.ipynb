{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMA 7 - WEB SCRAPPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estos ejercicios necesitarás, entre otras, las librerías beautifulsoup4 y requests.\n",
    "Para instalarlas ejecuta en una celda del jupyter:\n",
    "    \n",
    "    !pip install requests\n",
    "    !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "### Antes de empezar con el web scrapping es conveniente recordar la gestión de errores. \n",
    "\n",
    "Es por ello necesario que en este primer programa se implemente el código necesario para verificar si una página existe o no. Capturaremos los errores HTTP y URL y en caso de que no de ninguno pintaremos el html de la página. Ejecutaremos el código frente a:\n",
    "\n",
    "- [https://www.elmundo.es](https://www.elmundo.es)\n",
    "- [https://gmail.com/fichero.asp](https://gmail.com/fichero.asp)\n",
    "- [https://www.meloinvento123.es](https://www.meloinvento123.es)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Solución:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen(\"https://www.elmundo.es\")\n",
    "except HTTPError as e:\n",
    "    print(\"HTTP error\")\n",
    "except URLError as e:\n",
    "    print(\"Server not found!\")\n",
    "else:\n",
    "    print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen(\"https://gmail.com/fichero.asp\")\n",
    "except HTTPError as e:\n",
    "    print(\"HTTP error\")\n",
    "except URLError as e:\n",
    "    print(\"Server not found!\")\n",
    "else:\n",
    "    print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen(\"https://www.meloinvento123.es\")\n",
    "except HTTPError as e:\n",
    "    print(\"HTTP error\")\n",
    "except URLError as e:\n",
    "    print(\"Server not found!\")\n",
    "else:\n",
    "    print(html.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2:\n",
    "\n",
    "### Escribe el código necesario para descargar y mostrar el contenido del fichero robot.txt de la web https://www.elmundo.es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Solución:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"https://www.elmundo.es/robots.txt\")\n",
    "test = response.text\n",
    "print(\"Contenido del fichero robots.txt de https://www.elmundo.es/\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3:\n",
    "\n",
    "### Escribe el código necesario para obtener todas las url de imágenes disponibles en la web [https://es.wikipedia.org/wiki/Nueva_York_(estado)](https://es.wikipedia.org/wiki/Nueva_York_(estado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Solución:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html = urlopen('https://es.wikipedia.org/wiki/Nueva_York_(estado)')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "images = bs.find_all('img', {'src':re.compile('.jpg')})\n",
    "for image in images: \n",
    "    print(image['src']+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4:\n",
    "\n",
    "### Escribe el código necesario para listar todos los ficheros .zip que contienen los viajes del servicio de préstamo de bicicletas en la ciudad de Nueva York: [https://s3.amazonaws.com/tripdata/](https://s3.amazonaws.com/tripdata/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Solución:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://s3.amazonaws.com/tripdata/'\n",
    "\n",
    "# load url content into soup\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'xml')\n",
    "\n",
    "# extract file names from soup\n",
    "files = soup.find_all('Key')\n",
    "clean_files = []\n",
    "for i in range(len(files)-1):\n",
    "    clean_files.append(files[i].get_text())\n",
    "    \n",
    "clean_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
